<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
            --secondary-color: #4CAF50;
            --background-color: #f5f5f5;
            --content-bg: #ffffff;
            --text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
			  --accent11: #4caf50;
		--accent12: #4cafff;
		--accent13: #ffaf50;
		--accent14: #821978;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
            --secondary-color: #388e3c;
            --background-color: #000000;
            --content-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #000000;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 2px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Меню навигации */
        .menu {
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }
		
		
		.menu-buttons {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: center; /* Изменено на center */
}

        .menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .menu-btn:hover {
            background-color: var(--secondary-color);
        }

        .theme-toggle {
            background: none;
            border: 10px solid transparent;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        /* Выделение важного */
        .important {
            background-color: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .note {
            background-color: rgba(50, 89, 128, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        /* Таблицы */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: rgba(0, 0, 0, 0.03);
        }

        /* Списки */
        ul, ol {
            padding-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Адаптивный дизайн */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .menu {
                flex-direction: column;
                gap: 15px;
            }
            
            .menu-buttons {
                width: 100%;
                justify-content: center;
            }
            
            .theme-toggle {
                margin-top: 10px;
            }
            
            .section {
                padding: 15px;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }
		
					.kmp11, .example {
      background: rgba(76, 175, 80, 0.1);
      border-left: 4px solid var(--accent11);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp12, .example {
      background: rgba(95, 182, 237, 0.1);
      border-left: 4px solid var(--accent12);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
 
		.kmp13, .example {
      background: rgba(205, 170, 110, 0.1);
      border-left: 4px solid var(--accent13);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp14, .example {
      background: rgba(205, 110, 200, 0.1);
      border-left: 4px solid var(--accent14);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
	.link-kmp1 {
            color: #fffee0; 
            background-color: #007bff;
            padding: 0em 0.3em; 
            margin: 0 0.5em; /* Добавляет 0.5em отступа справа и слева */
            text-decoration: none; 
            border-radius: 5px; 
            transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out;
				}
		.link-kmp1:hover,
		.link-kmp1:focus {
           color: #ffffff; 
           background-color: #0bb313; 
           text-decoration: none; 
        }
	
	
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Bayes</h1>
            <p>Байесианский подход в компьютерной лингвистике</p>
        </header>

        <nav class="menu">
            <div class="menu-buttons">
                <button class="menu-btn" onclick="scrollToSection('1')">Байес</button>
				<button class="menu-btn" onclick="scrollToSection('2')">Понятия</button>
                <button class="menu-btn" onclick="scrollToSection('3')">Теорема</button>
				<button class="menu-btn" onclick="scrollToSection('4')">Значение</button>
				<button class="menu-btn" onclick="scrollToSection('5')">LLM</button>
				
				
				
				
                				
                                    </div>
            <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
        </nav>

<section id="1" class="section">
    <h2 class="section-title">Томас Байес и основы байесианства</h2>
    <div class="001">
        <h3 class="001-title">Томас Байес (1701-1761)</h3>
        <div class="001-card">
            <p>Томас Байес был английским пресвитерианским священником, философом и математиком. Его работа "Эссе о решении проблемы в доктрине шансов" была опубликована посмертно в 1763 году и заложила основы байесовской статистики.</p>
            <p>Байес разработал математический подход к обновлению убеждений на основе новых данных, что стало революционным для понимания вероятности и статистического вывода.</p>
            <p><strong>Основные достижения:</strong></p>
            <ul>
                <li>Формулировка теоремы об условной вероятности</li>
                <li>Введение понятия априорной и апостериорной вероятности</li>
                <li>Создание основ для байесовского вывода</li>
            </ul>
        </div>
        <div class="001-card">
            <h4>Байесианство как философский подход</h4>
            <p>Байесианство представляет собой интерпретацию вероятности как степени уверенности в истинности утверждения. В отличие от частотного подхода, байесианство позволяет работать с единичными событиями и обновлять убеждения по мере поступления новой информации.</p>
            <p><strong>Ключевые принципы байесианства:</strong></p>
            <ul>
                <li>Вероятность как мера неопределённости</li>
                <li>Обновление убеждений через новые данные</li>
                <li>Использование априорных знаний</li>
                <li>Итеративное уточнение гипотез</li>
            </ul>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Байесианский подход особенно ценен в лингвистике, где часто приходится работать с неполными данными и обновлять модели по мере получения новой информации.</div>
</section>

<section id="2" class="section">
    <h2 class="section-title">Базовые понятия теории вероятностей</h2>
    <div class="002">
        <h3 class="002-title">Фундаментальные концепции</h3>
        <div class="002-card">
            <h4>Условная вероятность P(A|B)</h4>
            <p>Условная вероятность P(A|B) — это вероятность наступления события A при условии, что событие B уже произошло. Читается как "вероятность A при условии B".</p>
            <p>Формула: P(A|B) = P(A ∩ B) / P(B), где P(B) > 0</p>
            <p><strong>Лингвистический пример:</strong> Вероятность того, что следующее слово будет "книга" при условии, что предыдущее слово было "интересная".</p>
        </div>
        <div class="002-card">
            <h4>Совместная вероятность P(A ∩ B)</h4>
            <p>Совместная вероятность P(A ∩ B) — это вероятность одновременного наступления событий A и B. Обозначается также как P(A, B).</p>
            <p>Формула: P(A ∩ B) = P(A|B) × P(B) = P(B|A) × P(A)</p>
            <p><strong>Лингвистический пример:</strong> Вероятность того, что в тексте встретится биграмма "красивый цветок".</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Тип вероятности</th>
                    <th>Обозначение</th>
                    <th>Пример в лингвистике</th>
                </tr>
            </thead>
            <tr>
                <td>Безусловная</td>
                <td>P(A)</td>
                <td>Вероятность слова "дом" в корпусе</td>
            </tr>
            <tr>
                <td>Условная</td>
                <td>P(A|B)</td>
                <td>Вероятность "дом" после артикля "the"</td>
            </tr>
            <tr>
                <td>Совместная</td>
                <td>P(A ∩ B)</td>
                <td>Вероятность последовательности "the house"</td>
            </tr>
        </table>
    </div>
	
	
	<div class="005-card">
            <h3>Априорная вероятность в языке</h3>
            <p>Априорная вероятность отражает наши предварительные знания о языковых явлениях до анализа конкретного текста:</p>
            <ul>
                <li>Частотность слов в языке (частотные словари)</li>
                <li>Вероятность грамматических конструкций</li>
                <li>Распределение тем в корпусе текстов</li>
                <li>Стилистические особенности жанров</li>
            </ul>
            <p><strong>Пример:</strong> P(слово="the") ≈ 0.07 в английском языке — это априорное знание о частотности артикля.</p>
        </div>
        <div class="005-card">
            <h3>Апостериорная вероятность в языке</h3>
            <p>Апостериорная вероятность — это уточнённая оценка после анализа конкретного контекста:</p>
            <ul>
                <li>Вероятность слова с учётом окружающего контекста</li>
                <li>Уточнённая оценка языка текста после анализа</li>
                <li>Вероятность темы после прочтения документа</li>
                <li>Оценка авторства на основе стилистических маркеров</li>
            </ul>
            <p><strong>Пример:</strong> P(следующее_слово="bank"|предыдущее="river") > P(следующее_слово="bank"|предыдущее="money")</p>
        </div>
    	
	
</section>

<section id="3" class="section">
    <h2 class="section-title">Теорема Байеса</h2>
    <div class="003">
        <h3 class="003-title">Формулировка и компоненты</h3>
        <div class="003-card">
            <h4>Основная формула</h4>
            <p>Теорема Байеса устанавливает связь между условными вероятностями:</p>
            <p><strong>P(H|D) = P(D|H) × P(H) / P(D)</strong></p>
            <p>где:</p>
            <ul>
                <li>H — гипотеза (hypothesis)</li>
                <li>D — данные/свидетельства (data/evidence)</li>
            </ul>
        </div>
        <div class="003-card">
            <h4>Компоненты формулы</h4>
            <p><strong>P(H|D) — Апостериорная вероятность:</strong> Вероятность гипотезы после получения данных. Это то, что мы хотим найти.</p>
            <p><strong>P(D|H) — Правдоподобие (Likelihood):</strong> Вероятность наблюдения данных при условии истинности гипотезы. Насколько хорошо гипотеза объясняет данные.</p>
            <p><strong>P(H) — Априорная вероятность:</strong> Начальная вероятность гипотезы до получения данных. Наши предварительные убеждения.</p>
            <p><strong>P(D) — Маргинальная вероятность:</strong> Общая вероятность наблюдения данных. Нормализующий фактор.</p>
        </div>
        <div class="003-card">
            <h4>Расширенная форма</h4>
            <p>Для полного набора взаимоисключающих гипотез H₁, H₂, ..., Hₙ:</p>
            <p><strong>P(Hᵢ|D) = P(D|Hᵢ) × P(Hᵢ) / Σⱼ P(D|Hⱼ) × P(Hⱼ)</strong></p>
            <p>Знаменатель представляет собой сумму по всем возможным гипотезам.</p>
        </div>
    </div>
    <div class="kmp14"><strong>Пояснение:</strong> Теорема Байеса позволяет "переворачивать" условные вероятности: зная P(D|H), мы можем найти P(H|D).</div>

    <div class="004">
        <h3 class="004-title">Наивный байесовский классификатор</h3>
        <div class="004-card">
            <h4>Предположение о независимости</h4>
            <p>Наивный байесовский классификатор делает сильное упрощающее предположение: все признаки (features) условно независимы друг от друга при данном классе. Это предположение редко выполняется в реальности, особенно в языке.</p>
            <p><strong>Математически:</strong> P(x₁, x₂, ..., xₙ|c) = P(x₁|c) × P(x₂|c) × ... × P(xₙ|c)</p>
            <p>где x₁, x₂, ..., xₙ — признаки, c — класс.</p>
        </div>
        <div class="004-card">
            <h4>Почему это работает в лингвистике?</h4>
            <p>Несмотря на нереалистичность предположения о независимости слов, наивный Байес показывает удивительно хорошие результаты в задачах обработки текста:</p>
            <ul>
                <li>Простота вычислений и масштабируемость</li>
                <li>Устойчивость к шуму в данных</li>
                <li>Хорошая производительность при малых обучающих выборках</li>
                <li>Эффективность для высокоразмерных данных (большие словари)</li>
            </ul>
            <p><strong>Пример нарушения независимости:</strong> Слова "Нью" и "Йорк" явно зависимы, но наивный Байес рассматривает их как независимые признаки.</p>
        </div>
    </div>
    <div class="kmp11"><strong>Примечание:</strong> Исследования показывают, что нарушение предположения о независимости часто не критично для качества классификации.</div>
</section>




<section id="4" class="section">
    <h2 class="section-title">Значение в квантитативной лингвистике</h2>
    <div class="006">
        <h3 class="006-title">Роль байесовских методов</h3>
        <div class="006-card">
            <h4>Основные области применения</h4>
            <p>Байесовские методы стали фундаментальными инструментами в квантитативной лингвистике:</p>
            <ul>
                <li>Статистическое моделирование языка</li>
                <li>Корпусная лингвистика и анализ частотностей</li>
                <li>Компьютерная лингвистика и NLP</li>
                <li>Психолингвистические исследования</li>
                <li>Социолингвистический анализ вариативности</li>
            </ul>
        </div>
        <div class="006-card">
            <h4>Преимущества байесовского подхода</h4>
            <p><strong>Работа с неопределённостью:</strong> Язык inherently неоднозначен, байесовские методы естественно моделируют эту неопределённость.</p>
            <p><strong>Инкорпорация предварительных знаний:</strong> Лингвистические теории и эмпирические наблюдения могут быть включены как априорные вероятности.</p>
            <p><strong>Обновление моделей:</strong> По мере получения новых данных модели могут адаптироваться без полной переработки.</p>
            <p><strong>Интерпретируемость:</strong> Вероятностные выводы легче интерпретировать, чем "чёрные ящики" некоторых современных методов.</p>
        </div>
    </div>

    <div class="010">
        <h3 class="010-title">Практические достоинства</h3>
        <div class="010-card">
            <h4>Вычислительная эффективность</h4>
            <p><strong>Простота реализации:</strong> Наивный Байес требует только подсчёта частот и умножения вероятностей.</p>
            <p><strong>Линейная сложность:</strong> O(n×d) для классификации, где n — количество классов, d — количество признаков.</p>
            <p><strong>Параллелизация:</strong> Вычисления легко распараллеливаются для больших данных.</p>
            <p><strong>Инкрементальное обучение:</strong> Модель легко обновляется при поступлении новых данных без полного переобучения.</p>
        </div>
        <div class="010-card">
            <h4>Работа с большими данными</h4>
            <p><strong>Масштабируемость:</strong> Эффективно работает с миллионами документов и сотнями тысяч признаков.</p>
            <p><strong>Разреженные данные:</strong> Хорошо справляется с высокоразмерными разреженными векторами (bag-of-words).</p>
            <p><strong>Малые выборки:</strong> Даёт разумные результаты даже при ограниченных обучающих данных благодаря априорным вероятностям.</p>
        </div>
        <div class="010-card">
            <h4>Применение в реальных системах</h4>
            <p><strong>Google Translate (ранние версии):</strong> Использовал байесовские модели для статистического машинного перевода.</p>
            <p><strong>Фильтры спама:</strong> Gmail и другие почтовые сервисы применяют варианты наивного Байеса.</p>
            <p><strong>Sentiment Analysis:</strong> Анализ тональности отзывов и социальных медиа.</p>
            <p><strong>Автодополнение и коррекция:</strong> Клавиатуры смартфонов используют байесовские модели для предсказания слов.</p>
        </div>
    </div>
</section>

<section id="5" class="section">
    <h2 class="section-title">Байесовские принципы в LLM</h2>
    <div class="011">
        <h3 class="011-title">Фундаментальная связь</h3>
        <div class="011-card">
            <p>LLM  используют нейронные архитектуры, но в их основе лежат байесовские принципы:</p>
            <p><strong>Языковое моделирование:</strong> P(следующее_слово|контекст) — это условная вероятность, оцениваемая моделью.</p>
            <p><strong>Обучение как байесовский вывод:</strong> Параметры модели можно интерпретировать как апостериорное распределение после наблюдения данных.</p>
        </div>
        <div class="011-card">
            <h4>Байесовские аспекты в LLM</h4>
            <p><strong>Attention механизм:</strong> Можно рассматривать как вычисление условных вероятностей важности разных частей контекста.</p>
            <p><strong>Prompt engineering:</strong> Изменение промпта — это по сути изменение априорной информации для модели.</p>
            <p><strong>Few-shot learning:</strong> Примеры в промпте действуют как данные для байесовского обновления внутренних представлений.</p>
            <p><strong>Uncertainty quantification:</strong> Современные исследования добавляют байесовские методы для оценки неопределённости предсказаний LLM.</p>
        </div>
        <div class="011-card">
            <h4>Преимущества байесовского взгляда на LLM</h4>
            <ul>
                <li>Интерпретируемость: понимание того, как модель обновляет "убеждения"</li>
                <li>Калибровка: оценка достоверности генерируемых ответов</li>
                <li>Эффективная адаптация: использование априорных знаний для fine-tuning</li>
                <li>Робастность: байесовские методы помогают избежать переобучения</li>
            </ul>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Понимание байесовских принципов помогает лучше использовать и интерпретировать современные языковые модели, даже если они реализованы через нейронные сети.</div>
<div class="014">
        <h3 class="014-title">Современные развития байесовских методов</h3>
        <div class="014-card">
            <h4>Байесовские нейронные сети</h4>
            <p>Комбинация байесовского вывода с глубоким обучением для оценки неопределённости в предсказаниях нейронных сетей.</p>
            <p><strong>Применения в NLP:</strong></p>
            <ul>
                <li>Оценка достоверности машинного перевода</li>
                <li>Калибровка confidence scores в классификации текстов</li>
                <li>Active learning для эффективной разметки данных</li>
            </ul>
        </div>
        <div class="014-card">
            <h4>Вариационный байесовский вывод</h4>
            <p>Аппроксимация сложных апостериорных распределений через оптимизацию.</p>
            <p><strong>Преимущества:</strong></p>
            <ul>
                <li>Масштабируемость на большие датасеты</li>
                <li>Возможность работы со сложными моделями</li>
                <li>Автоматический выбор сложности модели</li>
            </ul>
        </div>
        <div class="014-card">
            <h4>Байесовская оптимизация гиперпараметров</h4>
            <p>Использование байесовских методов для эффективного поиска оптимальных гиперпараметров моделей NLP.</p>
            <p><strong>Применения:</strong></p>
            <ul>
                <li>Настройка архитектуры нейронных сетей</li>
                <li>Оптимизация параметров токенизации</li>
                <li>Выбор оптимального размера эмбеддингов</li>
            </ul>
        </div>
    </div>
	
</section>





<footer class="footer">
<div class="container">
<p>© 2025 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>
    <script>
        // Функция для плавной прокрутки к разделу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            const menuHeight = document.querySelector('.menu').offsetHeight;
            
            window.scrollTo({
                top: section.offsetTop - menuHeight - 20,
                behavior: 'smooth'
            });
        }

        // Функция для переключения темы
        document.getElementById('themeToggle').addEventListener('click', function() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            this.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });
    </script>
</body>
</html>