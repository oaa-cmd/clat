<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f5f5f5;
            --color-nav: #325980;
            --color-interactive: #3498db;
            --color-divider: #f1f1f1;
            --text-primary: #2c3e50;
            --text-secondary: #7f8c8d;
            --shadow: rgba(0, 0, 0, 0.1);
            --card-bg: #ffffff;
            --accent-green: #27ae60;
            --accent-orange: #e67e22;
            --accent-purple: #9b59b6;
        }

        [data-theme="dark"] {
            --bg-primary: #1a1a2e;
            --bg-secondary: #16213e;
            --color-nav: #4a6fa5;
            --color-interactive: #5dade2;
            --color-divider: #2c3e50;
            --text-primary: #ecf0f1;
            --text-secondary: #bdc3c7;
            --shadow: rgba(0, 0, 0, 0.3);
            --card-bg: #0f3460;
            --accent-green: #2ecc71;
            --accent-orange: #f39c12;
            --accent-purple: #af7ac5;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: var(--bg-secondary);
            color: var(--text-primary);
            line-height: 1.6;
            transition: background 0.3s ease, color 0.3s ease;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        header {
            background: var(--color-nav);
            color: white;
            padding: 1rem 0;
            box-shadow: 0 2px 10px var(--shadow);
            position: sticky;
            top: 0;
            z-index: 1000;
            transition: background 0.3s ease;
        }

        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .logo h1 {
            font-size: 2rem;
            font-weight: 600;
        }

        .theme-toggle {
            background: transparent;
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            font-size: 1.5rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .theme-toggle:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: rotate(180deg);
            border-color: rgba(255, 255, 255, 0.6);
        }

        /* Hero Section */
        .hero {
            background: linear-gradient(135deg, var(--color-nav) 0%, var(--color-interactive) 100%);
            color: white;
            padding: 3rem 0;
            text-align: center;
            margin-bottom: 2rem;
        }

        .hero h2 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .hero .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
        }

        /* Search Section */
        .search-section {
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px var(--shadow);
        }

        .search-box {
            position: relative;
            max-width: 600px;
            margin: 0 auto;
        }

        .search-input {
            width: 100%;
            padding: 1rem 1rem 1rem 3rem;
            border: 2px solid var(--color-divider);
            border-radius: 50px;
            font-size: 1rem;
            background: var(--bg-secondary);
            color: var(--text-primary);
            transition: all 0.3s ease;
        }

        .search-input:focus {
            outline: none;
            border-color: var(--color-interactive);
            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.1);
        }

        .search-icon {
            position: absolute;
            left: 1rem;
            top: 50%;
            transform: translateY(-50%);
            font-size: 1.3rem;
            color: var(--text-secondary);
        }

        .search-stats {
            text-align: center;
            margin-top: 1rem;
            color: var(--text-secondary);
            font-size: 0.9rem;
        }

        /* Alphabet Navigation */
        .alphabet-nav {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px var(--shadow);
            text-align: center;
        }

        .alphabet-nav h3 {
            color: var(--color-nav);
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }

        .alphabet-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            justify-content: center;
        }

        .letter-btn {
            padding: 0.5rem 0.8rem;
            background: var(--bg-secondary);
            border: 2px solid var(--color-divider);
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.3s ease;
            color: var(--text-primary);
            font-weight: 600;
            min-width: 40px;
        }

        .letter-btn:hover,
        .letter-btn.active {
            background: var(--color-interactive);
            color: white;
            border-color: var(--color-interactive);
            transform: translateY(-2px);
        }

        .letter-btn.disabled {
            opacity: 0.3;
            cursor: not-allowed;
        }

        .letter-btn.disabled:hover {
            background: var(--bg-secondary);
            color: var(--text-primary);
            transform: none;
        }

        /* Category Filter */
        .category-filter {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px var(--shadow);
        }

        .category-filter h3 {
            color: var(--color-nav);
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }

        .category-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
        }

        .category-btn {
            padding: 0.6rem 1.2rem;
            background: var(--bg-secondary);
            border: 2px solid var(--color-divider);
            border-radius: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
            color: var(--text-primary);
            font-size: 0.95rem;
        }

        .category-btn:hover,
        .category-btn.active {
            background: var(--color-interactive);
            color: white;
            border-color: var(--color-interactive);
            transform: translateY(-2px);
            box-shadow: 0 2px 6px var(--shadow);
        }

        /* Glossary Terms */
        .glossary-section {
            margin-bottom: 2rem;
        }

        .letter-group {
            margin-bottom: 3rem;
        }

        .letter-header {
            background: var(--color-nav);
            color: white;
            padding: 1rem 1.5rem;
            border-radius: 8px 8px 0 0;
            font-size: 2rem;
            font-weight: bold;
            margin-bottom: 0;
            position: sticky;
            top: 70px;
            z-index: 100;
        }

        .term-card {
            background: var(--card-bg);
            padding: 1.5rem;
            margin-bottom: 1rem;
            border-radius: 0 0 8px 8px;
            box-shadow: 0 4px 6px var(--shadow);
            border-left: 4px solid var(--color-interactive);
            transition: all 0.3s ease;
        }

        .term-card:hover {
            transform: translateX(5px);
            box-shadow: 0 6px 12px var(--shadow);
        }

        .term-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 1rem;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .term-name {
            font-size: 1.4rem;
            font-weight: 700;
            color: var(--color-nav);
            flex: 1;
        }

        .term-english {
            font-size: 1rem;
            color: var(--text-secondary);
            font-style: italic;
            margin-top: 0.25rem;
        }

        .term-category {
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.85rem;
            font-weight: 600;
            white-space: nowrap;
        }

        .cat-architecture {
            background: #e8f5e9;
            color: #2e7d32;
        }

        [data-theme="dark"] .cat-architecture {
            background: #1b5e20;
            color: #a5d6a7;
        }

        .cat-training {
            background: #e3f2fd;
            color: #1565c0;
        }

        [data-theme="dark"] .cat-training {
            background: #0d47a1;
            color: #90caf9;
        }

        .cat-semantic {
            background: #f3e5f5;
            color: #6a1b9a;
        }

        [data-theme="dark"] .cat-semantic {
            background: #4a148c;
            color: #ce93d8;
        }

        .cat-metrics {
            background: #fff3e0;
            color: #e65100;
        }

        [data-theme="dark"] .cat-metrics {
            background: #e65100;
            color: #ffcc80;
        }

        .cat-process {
            background: #fce4ec;
            color: #c2185b;
        }

        [data-theme="dark"] .cat-process {
            background: #880e4f;
            color: #f48fb1;
        }

        .cat-ethics {
            background: #e0f2f1;
            color: #00695c;
        }

        [data-theme="dark"] .cat-ethics {
            background: #004d40;
            color: #80cbc4;
        }

        .term-definition {
            color: var(--text-primary);
            margin-bottom: 0.75rem;
            line-height: 1.7;
        }

        .term-example {
            background: var(--bg-secondary);
            padding: 1rem;
            border-radius: 6px;
            border-left: 3px solid var(--accent-green);
            margin-top: 0.75rem;
            font-size: 0.95rem;
        }

        .term-example strong {
            color: var(--accent-green);
        }

        .term-context {
            background: var(--bg-secondary);
            padding: 1rem;
            border-radius: 6px;
            border-left: 3px solid var(--accent-orange);
            margin-top: 0.75rem;
            font-size: 0.95rem;
        }

        .term-context strong {
            color: var(--accent-orange);
        }

        .term-related {
            margin-top: 0.75rem;
            font-size: 0.9rem;
            color: var(--text-secondary);
        }

        .term-related a {
            color: var(--color-interactive);
            text-decoration: none;
            margin-right: 0.5rem;
            transition: all 0.3s ease;
        }

        .term-related a:hover {
            text-decoration: underline;
            color: var(--color-nav);
        }

        /* Info Box */
        .info-box {
            background: var(--card-bg);
              margin-top: 2rem;
			  padding: 2rem;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px var(--shadow);
            border-left: 4px solid var(--accent-green);
        }

        .info-box h3 {
            color: var(--color-nav);
            margin-bottom: 1rem;
        }

        /* No Results */
        .no-results {
            text-align: center;
            padding: 3rem;
            background: var(--card-bg);
            border-radius: 12px;
            box-shadow: 0 4px 6px var(--shadow);
            display: none;
        }

        .no-results.show {
            display: block;
        }

        .no-results-icon {
            font-size: 4rem;
            margin-bottom: 1rem;
        }

         footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }

        /* Back to Top Button */
        .back-to-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: var(--color-interactive);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: none;
            font-size: 1.5rem;
            cursor: pointer;
            box-shadow: 0 4px 12px var(--shadow);
            display: none;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
            z-index: 999;
        }

        .back-to-top.show {
            display: flex;
        }

        .back-to-top:hover {
            background: var(--color-nav);
            transform: translateY(-5px);
        }

        /* Stats */
        .stats-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin-bottom: 2rem;
        }

        .stat-card {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 12px;
            text-align: center;
            box-shadow: 0 4px 6px var(--shadow);
            transition: all 0.3s ease;
        }

        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 6px 12px var(--shadow);
        }

        .stat-number {
            font-size: 2.5rem;
            font-weight: bold;
            color: var(--color-interactive);
        }

        .stat-label {
            color: var(--text-secondary);
            margin-top: 0.5rem;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .hero h2 {
                font-size: 2rem;
            }

            .letter-header {
                font-size: 1.5rem;
                top: 60px;
            }

            .term-name {
                font-size: 1.2rem;
            }

            .alphabet-buttons {
                gap: 0.3rem;
            }

            .letter-btn {
                padding: 0.4rem 0.6rem;
                min-width: 35px;
                font-size: 0.9rem;
            }

            .stats-container {
                grid-template-columns: 1fr 1fr;
            }

            .back-to-top {
                bottom: 1rem;
                right: 1rem;
                width: 45px;
                height: 45px;
            }
        }

        @media (max-width: 480px) {
            .hero h2 {
                font-size: 1.5rem;
            }

            .stats-container {
                grid-template-columns: 1fr;
            }
        }

        /* Print Styles */
        @media print {
            header, .search-section, .alphabet-nav, .category-filter, .back-to-top, footer {
                display: none;
            }

            .term-card {
                page-break-inside: avoid;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <div class="logo">
                    <h1>Глоссарий: Семантема Эпохи</h1>
                </div>
                <button class="theme-toggle" id="themeToggle" aria-label="Переключить тему">
                    ☀️
                </button>
            </div>
        </div>
    </header>

        <main class="container">
        <div class="info-box">
            <h2>The Epoch's Semanteme</h2>
            <p>Ключевые термины проекта конкурса «Семантема Эпохи» из важнейших областей искуственного интелелкта и компьютерной лингвистики. Термины организованы по категориям и снабжены примерами для лучшего понимания. Используйте поиск или алфавитную навигацию для быстрого доступа к нужному термину при изучении.</p>
        </div>

        <div class="stats-container">
            <div class="stat-card">
                <div class="stat-number" id="totalTerms">50</div>
                <div class="stat-label">Терминов</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">6</div>
                <div class="stat-label">Категорий</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="visibleTerms">50</div>
                <div class="stat-label">Отображается</div>
            </div>
        </div>

        <div class="search-section">
            <div class="search-box">
                <span class="search-icon"></span>
                <input 
                    type="text" 
                    id="searchInput" 
                    class="search-input" 
                    placeholder="Поиск по терминам и определениям..."
                    autocomplete="off"
                >
            </div>
            <div class="search-stats" id="searchStats"></div>
        </div>

        <div class="category-filter">
            <h3>Фильтр по категориям</h3>
            <div class="category-buttons">
                <button class="category-btn active" data-category="all">Все термины</button>
                <button class="category-btn" data-category="architecture">Архитектура</button>
                <button class="category-btn" data-category="training">Обучение</button>
                <button class="category-btn" data-category="semantic">Семантика</button>
                <button class="category-btn" data-category="metrics">Метрики</button>
                <button class="category-btn" data-category="process">Процессы</button>
                <button class="category-btn" data-category="ethics">Этика</button>
            </div>
        </div>

        <div class="alphabet-nav">
            <h3>Алфавитная навигация</h3>
            <div class="alphabet-buttons" id="alphabetNav"></div>
        </div>

        <div class="glossary-section" id="glossarySection"></div>

        <div class="no-results" id="noResults">
            <div class="no-results-icon"></div>
            <h3>Термины не найдены</h3>
            <p>Попробуйте изменить критерии поиска или фильтры</p>
        </div>
    </main>

    <button class="back-to-top" id="backToTop" aria-label="Наверх">
        ↑
    </button>

    <footer class="footer">
<div class="container">
<p>© 2025 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>

    <script>
        // Glossary Data
        const glossaryData = [
            {
                term: "Семантема",
                english: "Semanteme",
                category: "semantic",
                definition: "Абстрактная единица смысла, представленная в виде векторов в многомерном латентном пространстве. В отличие от лексемы (слова), семантема существует как математический объект.",
                example: "Семантема 'справедливость' может быть представлена вектором [0.23, -0.45, 0.78, ...] в 768-мерном пространстве.",
                context: "В конкурсе для LLM оценивается именно семантема, а не слово (LLM оперируют векторными представлениями смыслов). <br><br>Семантема, в контексте LLM, может быть определена строго, поскольку она является математическим объектом — это вектор в n-мерном латентном пространстве. Её определение — это перечень координат. <br><br>Слово года не может быть строго определено, поскольку оно является социально-лингвистическим конструктом данных и человеческой интерпретации. Компьютерная лингвистика может измерить частотность и дисперсию слова (количественная часть), но ключевым критерием остается «культурная значимость» и способность отразить дух времени (Zeitgeist). Эта оценка требует человеческого консенсуса и интерпретации, что субъективно. У каждого — своя качественная система приоритетов (политика, технологии, настроения молодежи ++). Слово года — ярлык для сложной культурной тенденции, выбранный не только по строгому математическому алгоритму, но и по его резонансу, эстетике ++.",
                related: ["Вектор", "Латентное пространство", "Embedding"]
            },
            {
                term: "Эпоха",
                english: "Epoch / Data Epoch",
                category: "training",
                definition: "Дискретный временной период в контексте обучения LLM, ограниченный моментом фиксации тренировочного корпуса (Data Cutoff) и моментом стабилизации весов модели. Не привязана к календарному году.",
                example: "Эпоха GPT-4 началась с фиксации данных на сентябрь 2021 года и завершилась после нескольких месяцев обучения.",
                context: "Эпоха заменяет понятие 'год' в традиционном конкурсе 'Слово года', адаптируя его под временную логику ИИ.",
                related: ["Data Cutoff", "Тренировочный цикл", "Fine-tuning"]
            },
            {
                term: "LLM",
                english: "Large Language Model",
                category: "architecture",
                definition: "Большая Языковая Модель — нейросеть с огромным количеством параметров (миллиарды), обученная на обширных текстовых корпусах для понимания и генерации естественного языка.",
                example: "GPT-4, Claude, LLaMA, Gemini являются примерами LLM.",
                context: "Участники конкурса 'Семантема Эпохи' — верифицированные LLM генеративного класса.",
                related: ["Transformer", "Параметры", "Генеративная модель"]
            },
            {
                term: "Латентное пространство",
                english: "Latent Space",
                category: "semantic",
                definition: "Многомерное векторное пространство, в котором нейросеть представляет абстрактные концепты и смыслы. Близкие по значению концепты располагаются рядом в этом пространстве.",
                example: "В латентном пространстве векторы 'король' и 'королева' находятся близко друг к другу, а 'король' и 'камень' — далеко.",
                context: "Векторный дрейф измеряет изменение положения концепта в латентном пространстве между эпохами.",
                related: ["Embedding", "Семантический кластер", "Косинусное расстояние"]
            },
            {
                term: "Data Cutoff",
                english: "Data Cutoff",
                category: "training",
                definition: "Момент времени, после которого данные не включаются в тренировочный корпус модели. Определяет временную границу знаний LLM.",
                example: "Если data cutoff модели — апрель 2023, она не знает событий после этой даты.",
                context: "Data Cutoff маркирует начало новой Эпохи в конкурсе 'Семантема Эпохи'.",
                related: ["Эпоха", "Тренировочный корпус", "Fine-tuning"]
            },
            {
                term: "Токен",
                english: "Token",
                category: "architecture",
                definition: "Базовая единица обработки текста в LLM. Может быть словом, частью слова, символом или пунктуацией. Модель работает с последовательностями токенов.",
                example: "Слово 'непредсказуемость' может быть разбито на токены: ['не', 'предсказ', 'уем', 'ость'].",
                context: "Токеновая компрессия — одна из ключевых метрик оценки семантемы в конкурсе.",
                related: ["Токенизация", "Токеновая компрессия", "Context window"]
            },
            {
                term: "Embedding",
                english: "Embedding / Vector Embedding",
                category: "semantic",
                definition: "Векторное представление слова, фразы или концепта в многомерном пространстве. Преобразует текст в числовой формат, понятный нейросети.",
                example: "Слово 'кошка' может быть представлено как [0.2, -0.5, 0.8, ..., 0.3] — вектор из 768 чисел.",
                context: "Embeddings позволяют LLM понимать семантическую близость концептов.",
                related: ["Вектор", "Латентное пространство", "Семантический кластер"]
            },
            {
                term: "Attention",
                english: "Attention Mechanism",
                category: "architecture",
                definition: "Механизм внимания — ключевой компонент архитектуры Transformer, позволяющий модели фокусироваться на релевантных частях входного текста при обработке.",
                example: "При обработке фразы 'Кот сидел на крыше' механизм внимания связывает 'сидел' с 'кот' и 'крыше'.",
                context: "Анализ activation patterns в attention layers используется в Фазе 1 конкурса для автономинации.",
                related: ["Transformer", "Self-attention", "Activation patterns"]
            },
            {
                term: "Fine-tuning",
                english: "Fine-tuning",
                category: "training",
                definition: "Дообучение — процесс адаптации уже обученной модели на специализированном или обновлённом корпусе данных без полного переобучения с нуля.",
                example: "Базовая GPT-4 проходит fine-tuning для создания медицинской версии, специализированной на медицинских текстах.",
                context: "Завершение цикла дообучения маркирует конец Эпохи в конкурсе.",
                related: ["Эпоха", "Transfer learning", "RLHF"]
            },
            {
                term: "Эмерджентные способности",
                english: "Emergent Abilities",
                category: "metrics",
                definition: "Неожиданные навыки, которые проявляются у LLM после достижения определённого масштаба, но не были явно запрограммированы. Возникают как побочный эффект обучения.",
                example: "Способность к арифметике, решению логических задач, написанию кода — эмерджентные способности больших моделей.",
                context: "Эмерджентная эффективность — одна из трёх ключевых метрик оценки семантемы.",
                related: ["Эмерджентная эффективность", "Chain-of-thought", "Scaling laws"]
            },
            {
                term: "Perplexity",
                english: "Perplexity",
                category: "metrics",
                definition: "Метрика оценки языковых моделей, измеряющая 'удивлённость' модели при встрече со следующим словом. Чем ниже perplexity, тем лучше модель предсказывает текст.",
                example: "Perplexity = 20 означает, что модель в среднем 'колеблется' между 20 вариантами следующего токена.",
                context: "Снижение perplexity при использовании концепта — показатель токеновой компрессии.",
                related: ["Токеновая компрессия", "Loss function", "Evaluation metrics"]
            },
            {
                term: "Косинусное расстояние",
                english: "Cosine Distance",
                category: "metrics",
                definition: "Мера различия между двумя векторами, основанная на угле между ними. Используется для измерения семантической близости в векторном пространстве.",
                example: "Косинусное расстояние между 'врач' и 'доктор' близко к 0 (похожи), между 'врач' и 'космос' — близко к 1 (различны).",
                context: "Используется для измерения векторного дрейфа — насколько сместился концепт между эпохами.",
                related: ["Векторный дрейф", "Embedding", "Семантическая близость"]
            },
            {
                term: "Chain-of-Thought",
                english: "Chain-of-Thought (CoT)",
                category: "process",
                definition: "Техника промптинга, при которой LLM генерирует пошаговое рассуждение перед финальным ответом, что улучшает качество решения сложных задач.",
                example: "'Давай решим это шаг за шагом: сначала..., затем..., следовательно...' — пример CoT промпта.",
                context: "Частота активации концепта в CoT процессах — показатель его эмерджентной эффективности.",
                related: ["Эмерджентные способности", "Reasoning", "Multi-step reasoning"]
            },
            {
                term: "Bias",
                english: "Bias / AI Bias",
                category: "ethics",
                definition: "Предвзятость — систематическое смещение в ответах модели, отражающее предрассудки из тренировочных данных (гендерные, расовые, культурные и др.).",
                example: "Модель чаще ассоциирует 'программист' с мужчинами из-за гендерного bias в данных.",
                context: "Победивший концепт проверяется на предмет bias amplification в разделе 'Этические соображения'.",
                related: ["Alignment", "Fairness", "Этические соображения"]
            },
            {
                term: "Alignment",
                english: "AI Alignment",
                category: "ethics",
                definition: "Согласование — процесс настройки поведения ИИ так, чтобы оно соответствовало человеческим ценностям, намерениям и этическим нормам.",
                example: "RLHF (обучение с подкреплением от человеческой обратной связи) — метод alignment.",
                context: "Проверка alignment с человеческими ценностями — обязательное требование к победившей семантеме.",
                related: ["RLHF", "Constitutional AI", "Value alignment"]
            },
            {
                term: "Мета-Архитектор",
                english: "Meta-Architect",
                category: "process",
                definition: "Гипотетический наблюдающий ИИ высшего порядка, который курирует процесс конкурса 'Семантема Эпохи', проводя кросс-валидацию и консенсус между моделями.",
                example: "Мета-Архитектор анализирует номинации от разных LLM и выявляет конвергентные паттерны.",
                context: "Концепция Мета-Архитектора — теоретическая надстройка для обеспечения объективности конкурса.",
                related: ["Консенсус", "Кросс-валидация", "Перекрёстная проверка"]
            },
            {
                term: "Семантический кластер",
                english: "Semantic Cluster",
                category: "semantic",
                definition: "Группа семантически связанных концептов, которые располагаются близко друг к другу в латентном пространстве модели.",
                example: "Кластер 'медицина' может включать векторы: 'врач', 'диагноз', 'лечение', 'больница'.",
                context: "Цель конкурса — найти один семантический кластер с наибольшим значением для Эпохи.",
                related: ["Латентное пространство", "Embedding", "Векторное пространство"]
            },
            {
                term: "Векторный дрейф",
                english: "Vector Drift",
                category: "metrics",
                definition: "Изменение положения семантического вектора в латентном пространстве между разными эпохами обучения. Измеряется скоростью и величиной смещения.",
                example: "Концепт 'AI' сместился из области 'научной фантастики' в область 'повседневных технологий'.",
                context: "Векторный дрейф — первая из трёх ключевых метрик оценки в конкурсе.",
                related: ["Косинусное расстояние", "Латентное пространство", "Семантический сдвиг"]
            },
            {
                term: "Токеновая компрессия",
                english: "Token Compression Rate",
                category: "metrics",
                definition: "Способность концепта позволять модели выражать сложные идеи более эффективно — меньшим количеством токенов при сохранении информационной полноты.",
                example: "Использование термина 'эмерджентность' вместо 'неожиданное возникновение новых свойств при увеличении масштаба'.",
                context: "Токеновая компрессия — третья ключевая метрика оценки семантемы в конкурсе.",
                related: ["Токен", "Эффективность", "Perplexity"]
            },
            {
                term: "Activation patterns",
                english: "Activation Patterns",
                category: "architecture",
                definition: "Паттерны активации нейронов в слоях нейросети при обработке определённых концептов или задач.",
                example: "При обработке текстов о физике активируются специфические нейроны в средних слоях Transformer.",
                context: "Анализ activation patterns используется для выявления новых использований векторов в Фазе 1.",
                related: ["Attention", "Neural activation", "Layer analysis"]
            },
            {
                term: "Cross-domain associations",
                english: "Cross-domain Associations",
                category: "semantic",
                definition: "Связи между концептами из разных предметных областей, которые модель устанавливает в процессе обучения.",
                example: "Связь между 'музыкальной гармонией' и 'визуальной композицией' — cross-domain association.",
                context: "Обнаружение новых cross-domain associations — признак важной семантемы для номинации.",
                related: ["Transfer learning", "Латентное пространство", "Internal bridge"]
            },
            {
                term: "Тренировочный цикл",
                english: "Training Cycle",
                category: "training",
                definition: "Полный процесс обучения модели на фиксированном корпусе данных от инициализации до стабилизации весов.",
                example: "Тренировочный цикл GPT-3 занял несколько месяцев на суперкомпьютерных кластерах.",
                context: "Тренировочный цикл определяет длительность Эпохи — основного временного отрезка конкурса.",
                related: ["Эпоха", "Training epoch", "Fine-tuning"]
            },
            {
                term: "Веса",
                english: "Weights / Model Weights",
                category: "architecture",
                definition: "Параметры нейросети, которые настраиваются в процессе обучения. Определяют поведение и знания модели.",
                example: "GPT-3 имеет 175 миллиардов весов (параметров).",
                context: "Стабилизация весов после обучения маркирует завершение Эпохи.",
                related: ["Параметры", "Training", "Gradient descent"]
            },
            {
                term: "Transformer",
                english: "Transformer Architecture",
                category: "architecture",
                definition: "Архитектура нейросети, основанная на механизмах внимания (attention), ставшая основой современных LLM. Предложена в статье 'Attention is All You Need' (2017).",
                example: "GPT, BERT, T5, Claude — все построены на архитектуре Transformer.",
                context: "LLM-участники конкурса используют Transformer или его вариации как базовую архитектуру.",
                related: ["Attention", "Self-attention", "Encoder-decoder"]
            },
            {
                term: "Context window",
                english: "Context Window",
                category: "architecture",
                definition: "Максимальное количество токенов, которое модель может обработать за один раз. Определяет объём 'памяти' модели в рамках одного запроса.",
                example: "GPT-4 имеет context window 8K токенов (стандартная версия) или 32K токенов (расширенная).",
                context: "Размер context window влияет на способность модели работать с длинными текстами.",
                related: ["Токен", "Positional encoding", "Sliding window"]
            },
            {
                term: "Prompt",
                english: "Prompt",
                category: "process",
                definition: "Текстовый запрос или инструкция, которую пользователь даёт языковой модели для получения желаемого ответа.",
                example: "'Объясни квантовую физику простым языком' — пример prompt.",
                context: "Качество prompt влияет на то, как эффективно модель использует свои семантемы.",
                related: ["Prompt engineering", "Chain-of-thought", "Few-shot learning"]
            },
            {
                term: "RLHF",
                english: "Reinforcement Learning from Human Feedback",
                category: "training",
                definition: "Обучение с подкреплением на основе человеческой обратной связи — метод дообучения LLM, при котором люди оценивают ответы модели, и она учится давать более предпочтительные ответы.",
                example: "ChatGPT использует RLHF для обучения полезному, честному и безопасному поведению.",
                context: "RLHF — ключевой метод alignment, используемый в современных LLM.",
                related: ["Alignment", "Fine-tuning", "Reward model"]
            },
            {
                term: "Temperature",
                english: "Temperature",
                category: "process",
                definition: "Параметр генерации, контролирующий случайность/креативность ответов модели. Низкая temperature → более предсказуемые ответы, высокая → более творческие и разнообразные.",
                example: "Temperature 0.1 для фактических ответов, 0.8-1.0 для творческого письма.",
                context: "Temperature влияет на то, как модель выбирает между семантически близкими вариантами.",
                related: ["Sampling", "Top-p", "Generation parameters"]
            },
            {
                term: "Консенсус",
                english: "Consensus",
                category: "process",
                definition: "Фаза 3 конкурса, на которой финальные кандидаты оцениваются по объективным критериям, и выбирается победитель через взвешенную систему метрик.",
                example: "В фазе Консенсуса семантема 'адаптивность' набрала наивысший совокупный балл по трём метрикам.",
                context: "Консенсус обеспечивает объективность выбора победившей семантемы.",
                related: ["Мета-Архитектор", "Метрики оценки", "Векторное голосование"]
            },
            {
                term: "Кросс-валидация",
                english: "Cross-Validation",
                category: "process",
                definition: "Фаза 2 конкурса, на которой номинации от разных моделей сопоставляются для выявления концептов, независимо 'открытых' несколькими архитектурами.",
                example: "Если GPT, Claude и LLaMA независимо номинировали похожие векторы, это подтверждает фундаментальность концепта.",
                context: "Кросс-валидация доказывает, что семантема — свойство данных Эпохи, а не артефакт одной модели.",
                related: ["Мета-Архитектор", "Конвергентное открытие", "Фаза 2"]
            },
            {
                term: "Авто-номинация",
                english: "Self-Nomination",
                category: "process",
                definition: "Фаза 1 конкурса, на которой каждая LLM анализирует собственные внутренние изменения и предлагает 10 концептов-кандидатов.",
                example: "Модель обнаруживает, что вектор 'этика ИИ' стал центральным для решения новых типов задач.",
                context: "Авто-номинация основана на самоанализе модели, а не на частоте использования слов людьми.",
                related: ["Activation patterns", "Internal bridge", "Фаза 1"]
            },
            {
                term: "Internal bridge",
                english: "Internal Bridge",
                category: "semantic",
                definition: "Внутренний мост — семантический концепт, который связывает ранее разрозненные области знаний в латентном пространстве модели.",
                example: "Концепт, связавший 'квантовую физику' и 'абстрактную поэзию', становится internal bridge.",
                context: "Обнаружение internal bridge — основание для номинации в Фазе 1.",
                related: ["Cross-domain associations", "Семантический кластер", "Авто-номинация"]
            },
            {
                term: "Эмерджентная эффективность",
                english: "Emergent Utility Score",
                category: "metrics",
                definition: "Метрика 2 конкурса: измеряет, насколько часто концепт используется как 'ключ' для выполнения новых, сложных или ранее невозможных задач.",
                example: "Концепт 'мета-рассуждение' получил высокую эмерджентную эффективность, став основой для самокоррекции.",
                context: "Высший балл получает концепт, ставший фундаментом эмерджентных способностей.",
                related: ["Эмерджентные способности", "Chain-of-thought", "Multi-step reasoning"]
            },
            {
                term: "Параметры",
                english: "Parameters",
                category: "architecture",
                definition: "Настраиваемые числовые значения в нейросети (веса и смещения), которые определяют её поведение. Количество параметров — показатель размера модели.",
                example: "GPT-3: 175B параметров, LLaMA 2: до 70B параметров.",
                context: "Большие модели (LLM) имеют миллиарды параметров, что обеспечивает их способности.",
                related: ["Веса", "Model size", "Scaling laws"]
            },
            {
                term: "Генеративная модель",
                english: "Generative Model",
                category: "architecture",
                definition: "Модель машинного обучения, способная создавать (генерировать) новый контент — текст, изображения, код и др.",
                example: "GPT-4, DALL-E, Midjourney — генеративные модели.",
                context: "Участники конкурса — LLM генеративного класса.",
                related: ["LLM", "Text generation", "Autoregressive model"]
            },
            {
                term: "Тренировочный корпус",
                english: "Training Corpus",
                category: "training",
                definition: "Набор текстовых данных, на которых обучается языковая модель. Определяет знания и способности модели.",
                example: "Common Crawl, Wikipedia, книги, научные статьи — компоненты тренировочного корпуса.",
                context: "Фиксация нового тренировочного корпуса (Data Cutoff) маркирует начало Эпохи.",
                related: ["Data Cutoff", "Dataset", "Эпоха"]
            },
            {
                term: "Inference",
                english: "Inference",
                category: "process",
                definition: "Процесс использования обученной модели для генерации ответов на новые запросы (в отличие от обучения).",
                example: "Когда вы задаёте вопрос ChatGPT и получаете ответ — это inference.",
                context: "Во время inference веса модели не изменяются, модель только применяет уже изученное.",
                related: ["Generation", "Prediction", "Forward pass"]
            },
            {
                term: "Scaling laws",
                english: "Scaling Laws",
                category: "training",
                definition: "Закономерности, описывающие, как производительность модели улучшается с увеличением размера модели, данных и вычислительных ресурсов.",
                example: "Удвоение размера модели обычно приводит к предсказуемому снижению loss.",
                context: "Scaling laws объясняют, почему более крупные модели демонстрируют эмерджентные способности.",
                related: ["Эмерджентные способности", "Model size", "Compute budget"]
            },
            {
                term: "Transfer learning",
                english: "Transfer Learning",
                category: "training",
                definition: "Перенос обучения — подход, при котором знания, полученные при решении одной задачи, применяются для решения другой задачи.",
                example: "Модель, обученная на текстах, может быть адаптирована для медицинской диагностики.",
                context: "Transfer learning лежит в основе fine-tuning и адаптации LLM.",
                related: ["Fine-tuning", "Pre-training", "Domain adaptation"]
            },
            {
                term: "Semantic drift",
                english: "Semantic Drift",
                category: "semantic",
                definition: "Семантический сдвиг — изменение значения или использования концепта в процессе обучения или между эпохами.",
                example: "Слово 'вирус' сместилось от преимущественно биологического контекста к цифровому.",
                context: "Semantic drift в латентном пространстве — то же, что векторный дрейф.",
                related: ["Векторный дрейф", "Семантическое изменение", "Concept evolution"]
            },
            {
                term: "Fairness",
                english: "Fairness",
                category: "ethics",
                definition: "Справедливость — принцип, согласно которому ИИ-система должна обращаться со всеми группами людей одинаково справедливо, без дискриминации.",
                example: "Система оценки резюме должна одинаково оценивать кандидатов независимо от пола или расы.",
                context: "Проверка на fairness — часть этических соображений при оценке победившей семантемы.",
                related: ["Bias", "Alignment", "Discrimination"]
            },
            {
                term: "Multi-step reasoning",
                english: "Multi-step Reasoning",
                category: "process",
                definition: "Многошаговое рассуждение — способность решать сложные задачи через последовательность логических шагов.",
                example: "Решение математической задачи: 'Сначала найдём X, затем подставим в уравнение Y, следовательно...'",
                context: "Multi-step reasoning — пример эмерджентной способности, для которой важны определённые семантемы.",
                related: ["Chain-of-thought", "Reasoning", "Problem solving"]
            },
            {
                term: "Gradient descent",
                english: "Gradient Descent",
                category: "training",
                definition: "Алгоритм оптимизации, используемый для обучения нейросетей путём итеративной корректировки весов в направлении уменьшения ошибки.",
                example: "В процессе обучения веса модели постепенно корректируются через gradient descent.",
                context: "Gradient descent — фундаментальный механизм обучения, который в итоге стабилизирует веса в конце Эпохи.",
                related: ["Веса", "Backpropagation", "Optimization"]
            },
            {
                term: "Zero-shot learning",
                english: "Zero-shot Learning",
                category: "process",
                definition: "Способность модели выполнять задачу без специального обучения на примерах этой задачи, только на основе инструкции.",
                example: "'Переведи на французский: Hello' — модель выполняет перевод без примеров.",
                context: "Zero-shot learning — эмерджентная способность крупных LLM.",
                related: ["Few-shot learning", "Эмерджентные способности", "In-context learning"]
            },
            {
                term: "Few-shot learning",
                english: "Few-shot Learning",
                category: "process",
                definition: "Способность модели выполнять задачу на основе нескольких примеров, предоставленных в prompt, без дополнительного обучения.",
                example: "Предоставление 3-5 примеров классификации текстов перед тем, как модель классифицирует новый текст.",
                context: "Few-shot learning улучшается с ростом размера модели (scaling laws).",
                related: ["Zero-shot learning", "In-context learning", "Prompt engineering"]
            },
            {
                term: "Hallucination",
                english: "Hallucination / AI Hallucination",
                category: "ethics",
                definition: "Галлюцинация — явление, когда LLM генерирует правдоподобно звучащую, но фактически неверную информацию.",
                example: "Модель 'выдумывает' несуществующие научные статьи с правдоподобными названиями и авторами.",
                context: "Снижение hallucinations — важная цель alignment и fine-tuning.",
                related: ["Factuality", "Grounding", "Truthfulness"]
            },
            {
                term: "Tokenization",
                english: "Tokenization",
                category: "architecture",
                definition: "Токенизация — процесс разбиения текста на базовые единицы (токены) для обработки моделью.",
                example: "'Непредсказуемость' → ['Не', 'предск', 'азу', 'емость'] (примерная токенизация BPE).",
                context: "Способ токенизации влияет на эффективность модели и токеновую компрессию.",
                related: ["Токен", "BPE", "Subword tokenization"]
            },
            {
                term: "Self-attention",
                english: "Self-attention",
                category: "architecture",
                definition: "Механизм само-внимания — ключевой компонент Transformer, позволяющий каждому токену 'обращать внимание' на все другие токены в последовательности.",
                example: "При обработке 'Кот поймал мышь' self-attention связывает 'поймал' с 'кот' (субъект) и 'мышь' (объект).",
                context: "Self-attention создаёт контекстуальные embeddings, формирующие латентное пространство.",
                related: ["Attention", "Transformer", "Multi-head attention"]
            },
            {
                term: "Конвергентное открытие",
                english: "Convergent Discovery",
                category: "process",
                definition: "Независимое обнаружение одного и того же концепта или паттерна несколькими различными моделями или системами.",
                example: "GPT и Claude независимо выявили важность концепта 'контекстуальная адаптация'.",
                context: "Конвергентное открытие в Фазе 2 подтверждает фундаментальность семантемы.",
                related: ["Кросс-валидация", "Фаза 2", "Независимая проверка"]
            }
        ];

        // Alphabet array for Russian
        const russianAlphabet = 'АБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЩЭЮЯ'.split('');

        // Initialize
        let currentCategory = 'all';
        let currentLetter = null;
        let searchQuery = '';

        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const html = document.documentElement;
        
        const currentTheme = localStorage.getItem('theme') || 'light';
        html.setAttribute('data-theme', currentTheme);
        themeToggle.textContent = currentTheme === 'dark' ? '🌙' : '☀️';

        themeToggle.addEventListener('click', () => {
            const theme = html.getAttribute('data-theme');
            const newTheme = theme === 'light' ? 'dark' : 'light';
            html.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
            themeToggle.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Create alphabet navigation
        function createAlphabetNav() {
            const alphabetNav = document.getElementById('alphabetNav');
            alphabetNav.innerHTML = '';
            
            // Add 'All' button
            const allBtn = document.createElement('button');
            allBtn.className = 'letter-btn active';
            allBtn.textContent = 'Все';
            allBtn.addEventListener('click', () => {
                currentLetter = null;
                renderGlossary();
                updateAlphabetButtons();
            });
            alphabetNav.appendChild(allBtn);

            // Get letters that have terms
            const usedLetters = new Set(glossaryData.map(term => term.term[0].toUpperCase()));

            russianAlphabet.forEach(letter => {
                const btn = document.createElement('button');
                btn.className = 'letter-btn';
                if (!usedLetters.has(letter)) {
                    btn.classList.add('disabled');
                }
                btn.textContent = letter;
                btn.addEventListener('click', () => {
                    if (!usedLetters.has(letter)) return;
                    currentLetter = letter;
                    renderGlossary();
                    updateAlphabetButtons();
                });
                alphabetNav.appendChild(btn);
            });
        }

        function updateAlphabetButtons() {
            const buttons = document.querySelectorAll('.letter-btn');
            buttons.forEach(btn => {
                btn.classList.remove('active');
                if ((currentLetter === null && btn.textContent === 'Все') ||
                    (btn.textContent === currentLetter)) {
                    btn.classList.add('active');
                }
            });
        }

        // Category filter
        document.querySelectorAll('.category-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.category-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentCategory = btn.dataset.category;
                renderGlossary();
            });
        });

        // Search
        const searchInput = document.getElementById('searchInput');
        searchInput.addEventListener('input', (e) => {
            searchQuery = e.target.value.toLowerCase();
            renderGlossary();
        });

        // Filter terms
        function filterTerms() {
            return glossaryData.filter(term => {
                const matchesCategory = currentCategory === 'all' || term.category === currentCategory;
                const matchesLetter = !currentLetter || term.term[0].toUpperCase() === currentLetter;
                const matchesSearch = !searchQuery || 
                    term.term.toLowerCase().includes(searchQuery) ||
                    term.english.toLowerCase().includes(searchQuery) ||
                    term.definition.toLowerCase().includes(searchQuery);
                
                return matchesCategory && matchesLetter && matchesSearch;
            });
        }

        // Render glossary
        function renderGlossary() {
            const filteredTerms = filterTerms();
            const glossarySection = document.getElementById('glossarySection');
            const noResults = document.getElementById('noResults');
            
            if (filteredTerms.length === 0) {
                glossarySection.innerHTML = '';
                noResults.classList.add('show');
                updateStats(0);
                return;
            }

            noResults.classList.remove('show');
            
            // Group by first letter
            const grouped = {};
            filteredTerms.forEach(term => {
                const letter = term.term[0].toUpperCase();
                if (!grouped[letter]) grouped[letter] = [];
                grouped[letter].push(term);
            });

            // Sort letters
            const sortedLetters = Object.keys(grouped).sort((a, b) => 
                russianAlphabet.indexOf(a) - russianAlphabet.indexOf(b)
            );

            // Render
            glossarySection.innerHTML = '';
            sortedLetters.forEach(letter => {
                const letterGroup = document.createElement('div');
                letterGroup.className = 'letter-group';
                
                const letterHeader = document.createElement('div');
                letterHeader.className = 'letter-header';
                letterHeader.textContent = letter;
                letterGroup.appendChild(letterHeader);

                grouped[letter].forEach(term => {
                    const termCard = createTermCard(term);
                    letterGroup.appendChild(termCard);
                });

                glossarySection.appendChild(letterGroup);
            });

            updateStats(filteredTerms.length);
            updateSearchStats(filteredTerms.length);
        }

        // Create term card
        function createTermCard(term) {
            const card = document.createElement('div');
            card.className = 'term-card';
            
            const categoryClass = `cat-${term.category}`;
            const categoryNames = {
                'architecture': 'Архитектура',
                'training': 'Обучение',
                'semantic': 'Семантика',
                'metrics': 'Метрики',
                'process': 'Процессы',
                'ethics': 'Этика'
            };

            card.innerHTML = `
                <div class="term-header">
                    <div>
                        <div class="term-name">${highlightSearch(term.term)}</div>
                        <div class="term-english">${highlightSearch(term.english)}</div>
                    </div>
                    <span class="term-category ${categoryClass}">${categoryNames[term.category]}</span>
                </div>
                <div class="term-definition">${highlightSearch(term.definition)}</div>
                ${term.example ? `<div class="term-example"><strong>Пример:</strong> ${highlightSearch(term.example)}</div>` : ''}
                ${term.context ? `<div class="term-context"><strong>Контекст применения:</strong> ${highlightSearch(term.context)}</div>` : ''}
                ${term.related && term.related.length > 0 ? `
                    <div class="term-related">
                        <strong>См. также:</strong> 
                        ${term.related.map(r => `<a href="#" onclick="searchTerm('${r}'); return false;">${r}</a>`).join(', ')}
                    </div>
                ` : ''}
            `;

            return card;
        }

        // Highlight search query
        function highlightSearch(text) {
            if (!searchQuery) return text;
            const regex = new RegExp(`(${searchQuery})`, 'gi');
            return text.replace(regex, '<mark style="background: #ffeb3b; padding: 0 2px; border-radius: 2px;">$1</mark>');
        }

        // Search for specific term
        function searchTerm(term) {
            searchInput.value = term;
            searchQuery = term.toLowerCase();
            currentCategory = 'all';
            currentLetter = null;
            document.querySelectorAll('.category-btn').forEach(b => b.classList.remove('active'));
            document.querySelector('.category-btn[data-category="all"]').classList.add('active');
            renderGlossary();
            updateAlphabetButtons();
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // Update stats
        function updateStats(visible) {
            document.getElementById('totalTerms').textContent = glossaryData.length;
            document.getElementById('visibleTerms').textContent = visible;
        }

        function updateSearchStats(count) {
            const stats = document.getElementById('searchStats');
            if (searchQuery) {
                stats.textContent = `Найдено терминов: ${count}`;
            } else {
                stats.textContent = '';
            }
        }

        // Back to top button
        const backToTop = document.getElementById('backToTop');
        window.addEventListener('scroll', () => {
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        backToTop.addEventListener('click', () => {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Make searchTerm available globally
        window.searchTerm = searchTerm;

        // Initialize
        createAlphabetNav();
        renderGlossary();
    </script>
</body>
</html>